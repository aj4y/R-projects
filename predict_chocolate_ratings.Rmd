---
title: "Train and evaluate models with tidymodels on Chocolate ratings data set"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 8, fig.height = 5)
library(tidyverse)
library(tidymodels)
library(tidytext)


```



```{r}

tuesdata <- tidytuesdayR::tt_load('2022-01-18')
tuesdata

chocolate <- tuesdata$chocolate

chocolate

```


## Explore data

Exploratory data analysis (EDA)
1. Ratings is in steps of 0.25 points, not really a continuous variable
2. Words like coca, sweet, nutty , fruit, roasty are most commonly used while describing the choclate taste
3. Country of bean origin has an impact on mean rating , but there is also huge variation
4. specific_bean_origin_or_bar_name also has an impact on mean rating

```{r}

chocolate %>% 
  ggplot(aes(rating))+geom_histogram()

chocolate_tokenized <- chocolate %>% 
  unnest_tokens(word,most_memorable_characteristics)

chocolate%>%
  count(country_of_bean_origin)%>%view()

chocolate %>%
  mutate(cocoa_percent = parse_number(cocoa_percent))%>%
  ggplot(aes(rating,cocoa_percent ))+geom_point()


chocolate %>% 
  group_by(country_of_bean_origin)%>%
  summarise(max_rating = max(rating),min_rating = min(rating),std_dev =sd(rating),rating=mean(rating))%>%
  mutate(country_of_bean_origin = fct_reorder(country_of_bean_origin,rating))%>%
  ggplot(aes(rating,country_of_bean_origin))+geom_errorbarh(aes(xmax=rating + std_dev,xmin=rating-std_dev))+geom_point()+
  labs(title =  'Mean rating for every country of origin',
       x = 'Rating',
       y="")


chocolate %>% 
  mutate(specific_bean_origin_or_bar_name = fct_lump(specific_bean_origin_or_bar_name,50))%>%
  group_by(specific_bean_origin_or_bar_name)%>%
  summarise(max_rating = max(rating),min_rating = min(rating),std_dev =sd(rating),rating=mean(rating))%>%
  mutate(specific_bean_origin_or_bar_name = fct_reorder(specific_bean_origin_or_bar_name,rating))%>%
  ggplot(aes(rating,specific_bean_origin_or_bar_name))+geom_errorbarh(aes(xmax=rating + std_dev,xmin=rating-std_dev))+geom_point()+
  labs(title =  'Mean rating for top 50 specific_bean_origin_or_bar_name',
       x = 'Rating',
       y="")




```



3. Words like cocoa, fruit, creamy, cherry, cardamom, cranberry, cinnamon, blackberry, balanced etc are correlated with high ratings of the chocolates. And pastey, chemical, cardboard,rubber, strong, bitter, metaletc are associated with lower ratings.

```{r}

chocolate_tokenized %>% 
  group_by(word)%>% 
  summarise(n = n(),
            rating = mean(rating))%>%
  ggplot(aes(n,rating))+geom_point()+
  geom_text(aes(label = word),check_overlap = T)+
  geom_hline(yintercept = mean(chocolate$rating),lty=2,color='red')+
  scale_x_log10()+
  labs(x = 'Frequency of most used words (log scale)',
       y = 'Ratings',
       title = ' Frequency of most used words vs Ratings' )

```


## Build models

- create training and testing sets
- create resampling folds from the *training* set

```{r}
set.seed(123)

choco_split <- initial_split(chocolate, strata = rating)
choco_train <- training(choco_split)
choco_test <- testing(choco_split)


set.seed(234)

choco_folds <- vfold_cv(choco_train,strata = rating) #Default is v = 10
choco_folds

```

Lets setup the pre-processing recipe flow  

```{r}
library(textrecipes)


choco_recipe <- 
  recipe( rating ~ most_memorable_characteristics+cocoa_percent , data = choco_train) %>%
  step_tokenize(most_memorable_characteristics)%>%
  step_tokenfilter(most_memorable_characteristics,max_tokens = 100)%>%
  step_tf(most_memorable_characteristics)%>%
  step_integer(cocoa_percent)%>%
  step_normalize(cocoa_percent)
  #step_other(country_of_bean_origin,threshold = 10)%>%
  #step_other(specific_bean_origin_or_bar_name, threshold = 10)%>%
  #step_dummy(all_nominal_predictors())
  
prep(choco_recipe) %>% bake(new_data=NULL)%>%
  view()

```


Let's create a [**model specification**](https://www.tmwr.org/models.html) for each model we want to try:
1. Lets fit a random-forest and svm model on the data using the ranger enginte

```{r}
ranger_spec <-
  rand_forest(trees = 500) %>% # define the type of algorithm you want to use
  set_engine("ranger") %>% # se the engine i.e. computational model to be used to fit the model
  set_mode("regression") #type of modeling problem i.e. regression, classification etc

ranger_spec

svm_spec <-
  svm_linear()%>%
  set_engine('LiblineaR')%>%
  set_mode("regression")

svm_spec

```

To set up your modeling code, consider using the [parsnip addin](https://parsnip.tidymodels.org/reference/parsnip_addin.html) or the [usemodels](https://usemodels.tidymodels.org/) package.

Now let's build a [**model workflow**](https://www.tmwr.org/workflows.html) combining each model specification with a data preprocessor:



```{r}
ranger_wf <- workflow(choco_recipe,ranger_spec)
svm_wf <- workflow(choco_recipe,svm_spec)



```

## Evaluate models

These models have no tuning parameters so we can evaluate them as they are. [Learn about tuning hyperparameters here.](https://www.tidymodels.org/start/tuning/)

```{r}

#doParallel::registerDoParallel()

contrl_preds <- control_resamples(save_pred = TRUE)

ranger_rs <- fit_resamples(
  ranger_wf,
  resamples = choco_folds,
  control = contrl_preds
)

svm_rs <- fit_resamples(
  svm_wf,
  resamples = choco_folds,
  control = contrl_preds
)

 ranger_rs$.predictions

svm_rs

```

How did these two models compare?

```{r}

collect_metrics(ranger_rs)
collect_metrics(svm_rs)


```

We can visualize these results

```{r}
bind_rows(
  collect_predictions(svm_rs)%>%
    mutate(model = 'svm'),
  collect_predictions(ranger_rs)%>%
    mutate(model='ranger')
)%>%
  ggplot(aes(rating,.pred,color=id))+geom_jitter()+
  facet_wrap(~model)


collect_predictions(svm_rs)%>%
  ggplot(aes(rating,.pred,color=id))+geom_jitter()


  

```


Final model , final_fitted object contains the final workflow that we can use for prediction later

```{r}
final_fitted <- last_fit(ranger_wf,choco_split)
collect_metrics(final_fitted)

final_wf <- extract_workflow(final_fitted)
predict(final_wf,choco_test)


extract_workflow(final_fitted)%>%
  tidy()%>%
  filter(term !='Bias')%>%
  group_by(estimate>0)%>%
  slice_max(abs(estimate),n=20)%>%
  #mutate(term=str_remove(term,"tf_most_memorable_characteristics_"))%>%
  mutate(term = fct_reorder(term,estimate))%>%
  ggplot(aes(estimate,term,fill=estimate>0))+geom_col()


```


Surprisingly, Cocoa percentage has very low to minimal impact on the ratings

